# ğŸ§  DocuMind - Intelligent RAG Chatbot

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-yellow)](https://huggingface.co/)

> Retrieval-Augmented Generation (RAG) chatbot avec fine-tuning LLM et recherche sÃ©mantique

**ğŸš§ Projet en dÃ©veloppement actif - Semaine du [Date]**

---

## ğŸ“‹ Table des matiÃ¨res

- [Ã€ propos](#Ã -propos)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [DÃ©veloppement](#dÃ©veloppement)
- [Technologies](#technologies)
- [Roadmap](#roadmap)
- [Auteur](#auteur)

---

## ğŸ¯ Ã€ propos

DocuMind est un systÃ¨me de question-rÃ©ponse intelligent basÃ© sur l'architecture RAG (Retrieval-Augmented Generation). Le systÃ¨me combine:

- **Retrieval sÃ©mantique** via embeddings et FAISS pour trouver les documents pertinents
- **GÃ©nÃ©ration de rÃ©ponses** avec un LLM fine-tunÃ© via LoRA
- **Citations automatiques** des sources pour garantir la traÃ§abilitÃ©
- **Interface web intuitive** avec Gradio

### ProblÃ¨me rÃ©solu

[Domaine spÃ©cifique] nÃ©cessite souvent de rechercher dans de nombreux documents pour rÃ©pondre Ã  des questions. DocuMind automatise ce processus en fournissant des rÃ©ponses prÃ©cises, contextualisÃ©es et sourcÃ©es en quelques secondes.

### Cas d'usage

- RÃ©ponse automatique aux FAQ
- Assistance Ã  la documentation technique
- Support client intelligent
- Recherche sÃ©mantique dans bases de connaissances

---

## âœ¨ FonctionnalitÃ©s

### ğŸ¯ Core Features

- [x] GÃ©nÃ©ration d'embeddings sÃ©mantiques (Sentence Transformers)
- [x] Indexation vectorielle rapide (FAISS)
- [x] Recherche par similaritÃ© cosinus
- [ ] Fine-tuning LLM avec LoRA
- [ ] Pipeline RAG end-to-end
- [ ] Interface chat Gradio
- [ ] Citations automatiques des sources

### ğŸš€ Features AvancÃ©es (PrÃ©vues)

- [ ] Multi-turn conversations avec contexte
- [ ] Re-ranking des documents rÃ©cupÃ©rÃ©s
- [ ] DÃ©tection d'hallucinations
- [ ] Support multi-langues
- [ ] API REST pour intÃ©gration

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DOCUMIND RAG SYSTEM                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Question   â”‚
â”‚  utilisateur â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RETRIEVAL PHASE                                          â”‚
â”‚                                                           â”‚
â”‚  1. Embedding de la question                             â”‚
â”‚     â””â”€> Sentence Transformer (all-MiniLM-L6-v2)         â”‚
â”‚                                                           â”‚
â”‚  2. Recherche similaritÃ© FAISS                           â”‚
â”‚     â””â”€> Top-K documents pertinents (K=3)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GENERATION PHASE                                         â”‚
â”‚                                                           â”‚
â”‚  3. Construction du prompt                               â”‚
â”‚     â””â”€> Context: [documents] + Question                  â”‚
â”‚                                                           â”‚
â”‚  4. GÃ©nÃ©ration rÃ©ponse                                   â”‚
â”‚     â””â”€> LLM fine-tunÃ© (Phi-3-mini + LoRA)               â”‚
â”‚                                                           â”‚
â”‚  5. Post-processing                                      â”‚
â”‚     â””â”€> Ajout citations + vÃ©rifications                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RÃ‰PONSE FINALE                                          â”‚
â”‚  â”œâ”€ RÃ©ponse gÃ©nÃ©rÃ©e                                      â”‚
â”‚  â”œâ”€ Sources citÃ©es                                       â”‚
â”‚  â””â”€ Score de confiance                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.9 ou supÃ©rieur
- 8 GB RAM minimum
- 10 GB espace disque disponible
- [UV](https://astral.sh/uv) (recommandÃ©) ou pip

### Installation rapide avec UV
```bash
# 1. Clone le repository
git clone https://github.com/[username]/documind-rag-chatbot.git
cd documind-rag-chatbot

# 2. Installe UV (si pas dÃ©jÃ  installÃ©)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 3. CrÃ©e l'environnement virtuel
uv venv

# 4. Active l'environnement
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate   # Windows

# 5. Installe les dÃ©pendances
uv pip install -r requirements.txt

# 6. VÃ©rifie l'installation
python scripts/test_installation.py
```

### Installation alternative avec pip
```bash
# Clone et navigue
git clone https://github.com/[username]/documind-rag-chatbot.git
cd documind-rag-chatbot

# Environnement virtuel
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# Installe dÃ©pendances
pip install -r requirements.txt
```

### Configuration
```bash
# Copie le template de configuration
cp .env.example .env

# Ã‰dite .env avec tes tokens
nano .env
```

**.env:**
```bash
# Hugging Face Token (optionnel pour API)
HF_TOKEN=your_token_here

# Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_MODEL=microsoft/Phi-3-mini-4k-instruct
TOP_K_DOCUMENTS=3
```

---

## ğŸ’» Utilisation

### DÃ©marrage rapide (quand terminÃ©)
```bash
# Active l'environnement
source .venv/bin/activate

# Lance l'interface Gradio
python app.py
```

Ouvre ton navigateur sur `http://localhost:7860`

### Utilisation en ligne de commande
```python
from src.rag_pipeline import RAGPipeline

# Initialise le pipeline
rag = RAGPipeline()

# Pose une question
question = "Comment fonctionne X?"
answer, sources = rag.answer(question)

print(f"RÃ©ponse: {answer}")
print(f"Sources: {sources}")
```

### API (Ã  venir)
```bash
# DÃ©marre le serveur API
python api/server.py

# RequÃªte exemple
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Comment faire Y?"}'
```

---

## ğŸ› ï¸ DÃ©veloppement

### Structure du projet
```
documind-rag-chatbot/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Documents sources bruts
â”‚   â”œâ”€â”€ processed/              # Embeddings et index FAISS
â”‚   â””â”€â”€ training/               # Dataset fine-tuning Q&A
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ embeddings/             # ModÃ¨les embeddings
â”‚   â””â”€â”€ fine_tuned/             # LLM fine-tunÃ© (LoRA adapters)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embeddings.py           # GÃ©nÃ©ration embeddings
â”‚   â”œâ”€â”€ retrieval.py            # SystÃ¨me FAISS retrieval
â”‚   â”œâ”€â”€ generation.py           # GÃ©nÃ©ration LLM
â”‚   â”œâ”€â”€ rag_pipeline.py         # Pipeline RAG complet
â”‚   â””â”€â”€ evaluation.py           # MÃ©triques et Ã©valuation
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_embeddings_test.ipynb
â”‚   â”œâ”€â”€ 03_fine_tuning.ipynb
â”‚   â””â”€â”€ 04_evaluation.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â”œâ”€â”€ test_generation.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ test_installation.py
â”œâ”€â”€ app.py                      # Interface Gradio
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### Workflow de dÃ©veloppement
```bash
# 1. CrÃ©e une branche pour ta feature
git checkout -b feature/nom-feature

# 2. Code et teste
python -m pytest tests/

# 3. VÃ©rifie le style (optionnel)
black src/
flake8 src/

# 4. Commit et push
git add .
git commit -m "feat: description"
git push origin feature/nom-feature
```

### Ajouter des documents
```bash
# Place tes documents dans data/raw/
# Format supportÃ©: .txt, .json, .csv

# GÃ©nÃ¨re les embeddings
python src/embeddings.py --input data/raw/ --output data/processed/
```

### Fine-tuning du modÃ¨le
```bash
# Voir notebook: notebooks/03_fine_tuning.ipynb
# Ou utilise Google Colab avec GPU gratuit
```

---

## ğŸ”§ Technologies

### Core ML/AI
- **[Transformers](https://huggingface.co/docs/transformers)** - Framework Hugging Face
- **[Sentence Transformers](https://www.sbert.net/)** - Embeddings sÃ©mantiques
- **[FAISS](https://faiss.ai/)** - Recherche vectorielle rapide
- **[PEFT](https://huggingface.co/docs/peft)** - Fine-tuning LoRA
- **[PyTorch](https://pytorch.org/)** - Deep learning framework

### Interface & Deployment
- **[Gradio](https://gradio.app/)** - Interface web interactive
- **[Hugging Face Spaces](https://huggingface.co/spaces)** - HÃ©bergement gratuit

### ModÃ¨les utilisÃ©s
- **Embeddings:** `sentence-transformers/all-MiniLM-L6-v2` (80 MB)
- **LLM:** `microsoft/Phi-3-mini-4k-instruct` (7.6 GB)
- **Fine-tuning:** LoRA (rank=8, alpha=16)

---

## ğŸ“Š Performances (Ã  venir)

| MÃ©trique | Valeur |
|----------|--------|
| PrÃ©cision rÃ©ponses | TBD% |
| Recall@3 retrieval | TBD% |
| Temps rÃ©ponse moyen | TBD s |
| Taux hallucination | < TBD% |
| Citations correctes | TBD% |

---

## ğŸ—“ï¸ Roadmap

### Semaine 1 (Actuel)
- [x] Setup projet et structure
- [x] Installation dÃ©pendances
- [ ] SystÃ¨me embeddings + FAISS
- [ ] Fine-tuning LLM avec LoRA
- [ ] Pipeline RAG complet
- [ ] Interface Gradio
- [ ] DÃ©ploiement Hugging Face Spaces

### AmÃ©liorations futures
- [ ] Multi-modal RAG (texte + images)
- [ ] GraphRAG pour donnÃ©es structurÃ©es
- [ ] Support multi-langues
- [ ] Re-ranking avancÃ©
- [ ] IntÃ©gration bases de donnÃ©es vectorielles (Pinecone, Weaviate)
- [ ] Monitoring et analytics production

---

## ğŸ“ˆ RÃ©sultats (Ã  complÃ©ter)

### Exemples de questions/rÃ©ponses

**Question:** [Exemple question]

**RÃ©ponse:** [RÃ©ponse gÃ©nÃ©rÃ©e]

**Sources:** 
- Document 1 (score: 0.89)
- Document 2 (score: 0.85)

---

## ğŸ¤ Contribution

Les contributions sont bienvenues! Pour contribuer:

1. Fork le projet
2. CrÃ©e ta branche (`git checkout -b feature/AmazingFeature`)
3. Commit tes changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvre une Pull Request

---

## ğŸ“ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¤ Auteur

**[Ton Nom]**

- GitHub: [@username](https://github.com/username)
- LinkedIn: [Ton profil](https://linkedin.com/in/username)
- Portfolio: [ton-site.com](https://ton-site.com)

---

## ğŸ™ Remerciements

- [Hugging Face](https://huggingface.co/) pour l'Ã©cosystÃ¨me transformers
- [Sentence Transformers](https://www.sbert.net/) pour les embeddings
- [FAISS](https://faiss.ai/) par Facebook Research
- CommunautÃ© ML pour les ressources et tutoriels

---

## ğŸ“š Ressources & RÃ©fÃ©rences

### Papers
- [RAG: Retrieval-Augmented Generation (2020)](https://arxiv.org/abs/2005.11401)
- [LoRA: Low-Rank Adaptation (2021)](https://arxiv.org/abs/2106.09685)
- [Dense Passage Retrieval (2020)](https://arxiv.org/abs/2004.04906)

### Tutoriels
- [Hugging Face RAG Course](https://huggingface.co/learn/cookbook)
- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/qa)

---

**â­ Si ce projet t'aide, n'hÃ©site pas Ã  lui donner une Ã©toile!**

---

*DerniÃ¨re mise Ã  jour: 21/10/2025*
*Version: 0.1.0 (Development)*